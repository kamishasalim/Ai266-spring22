<h1 align="center">Assignment - 3</h1>

## Group Members
| Student ID | Name | ML Technique |
| :---: | :---:  | :---:  |
| 11041 | Bilal Shoukat | Lidstone Smoothing
| 11070 | Kamisha Salim | KNN |
| 62803 | Murtaza Memon | 
| 64055 | Muhammad Kashan | Perceptron

## Problems Faced in the Assignment
### Bilal Shoukat (Lidstone Smoothing)


### Kamisha Salim (KNN)
The accuracy of this model was 50%-53% percent when the number of neighbours were 15 but after increasing just one more neighbour i.e. 16, the accuracy of this model significantly changed to 65%. Which means that increasing the amount of neighbours will also increase the accuracy of the model. The problem of accuracy was also solved by selecting the columns with the best variance (f_22, f_25, f_19, f_24, f_21, f_26) and also deleting column f_27 as it was an irrelevent column.

### Murtaza Memon


### Muhammad Kashan (Perceptron)


## Screenshot of Kaggle score
### Bilal Shoukat (Lidstone Smoothing)


### Kamisha Salim (KNN)
The k-nearest neighbors (KNN) algorithm is a simple, supervised machine learning algorithm that can be used to solve both classification and regression problems. It's easy to implement and understand, but has a major drawback of becoming significantly slow as the size of that data in use grows. It also takes a lot of time to train a model.

![Screenshot_2](https://user-images.githubusercontent.com/99355356/169399555-9586bd8b-8ab4-430e-8e04-31f3f1ed060c.png)

### Murtaza Memon


### Muhammad Kashan (Perceptron)
